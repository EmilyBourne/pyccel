name: Linux unit tests

on:
  workflow_dispatch:
    inputs:
      python_version:
        required: true
        type: string
      ref:
        required: false
        type: string
      check_run_id:
        required: false
        type: string

jobs:
  Linux:

    runs-on: ubuntu-latest
    name: Unit tests

    steps:
      - name: Get ref
        id: ref
        run: |
          ref = "${{ inputs.ref }}" or "${{ github.event.ref }}"
          with open("${{ github.output }}", "a") as f:
              print("ref=", ref, sep='', file=f)
        shell: python
      - uses: actions/checkout@v3
        with:
          ref: ${{ steps.ref.outputs.ref }}
      - name: Set up Python ${{ inputs.python_version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ inputs.python_version }}
      - name: "Setup"
        id: token
        run:
          python ci_tools/setup_check_run.py
        env:
          BOT_PEM: ${{ secrets.BOT_PEM }}
          GITHUB_RUN_ID: ${{ github.run_id }}
      - name: Coverage install
        uses: ./.github/actions/coverage_install
      - name: Fortran/C tests with pytest
        id: f_c_pytest
        timeout-minutes: 60
        uses: ./.github/actions/pytest_run
      - name: Python tests with pytest
        id: python_pytest
        timeout-minutes: 20
        uses: ./.github/actions/pytest_run_python
      - name: Parallel tests with pytest
        id: parallel
        timeout-minutes: 20
        uses: ./.github/actions/pytest_parallel
      - name: Test with valgrind for memory leaks
        id: valgrind
        uses: ./.github/actions/valgrind_run
      - name: Collect coverage information
        continue-on-error: True
        uses: ./.github/actions/coverage_collection
      - name: Run codacy-coverage-reporter
        uses: codacy/codacy-coverage-reporter-action@master
        continue-on-error: True
        with:
          project-token: ${{ secrets.CODACY_PROJECT_TOKEN }}
          coverage-reports: cobertura.xml
      - name: Save code coverage report
        uses: actions/upload-artifact@v3
        with:
          name: coverage-artifact
          path: cobertura.xml
          retention-days: 1
      - name: "Post completed"
        if: always()
        run:
          python ci_tools/complete_check_run.py steps.f_c_pytest.outcome steps.python_pytest.outcome steps.parallel.outcome steps.valgrind.outcome
        env:
          installation_token: ${{ steps.token.outputs.installation_token }}
          installation_token_exp: ${{ steps.token.outputs.installation_token_exp }}
          check_run_id: ${{ steps.check_create.outputs.check_id }}
          status: ${{ steps.status.outcome }}
